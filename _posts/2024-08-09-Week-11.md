---
layout: post
---

<!-- ## Difficulties

## Ideas

## Challenges

## Attempts to succeed

## Failures

## Advice -->

The meeting was postponed by two days due to personal reasons.

## Finished

### Added entering and scrolling result window

The fundamental function to have a better display of generating results.

<video width="100%" controls>
  <source src="{{ 'img/2024-08-09/frame_blender_scrolling_demo.mp4' | relative_url }}" type="video/mp4">
  Your browser does not support the video tag.
</video>

If the video doesn't play, please try this link: <https://drive.google.com/file/d/1vKdb6dCexjZJ8cyl7zawE8xxWnPI5hIo/view?usp=sharing>

### Made prompt templates

By making these prompt templates, we are able to take any number of frame names and embed them into prompts, 
like filling the blanks.

Supported prompt templates:

- Zero-shot prompting
- One-shot prompting
- Few-shot prompting
- Chain of Thought (CoT) prompting
- Rhetorical options

### Contemplating evaluation system

As is mentioned in the previous meetings, we are intending to implement an **evaluation system**, 
so that we can gather and store the feedback from users about the frame blending results. 
These evaluation information could be used for future analysing and training.

Currently, I plan to use files to store JSON-format evaluation data, 
since we are working on the HPC cluster and a persistent database might not be a good choice. 
Here is a JSON schema design by me for storing evaluation data. 
Parameters related to the generating process are to be stored, such as 

- `frame names`
- `prompt types`
- `blending result`
- `evaluations`

Particularly, for `evaluations` section, we will have the users input feedback from different dimensions,
including

- `completeness`
- `clarity`
- `relevance`
- `depth of understanding`
- `coherence`
- `execute time`
- `additional notes`

<center>
	<img src="{{ 'img/2024-08-09/evaluation_storage_schema.png' | relative_url }}" style="width: 60%;">
</center>

## Other Messages From The Weekly Meeting

Suzie pointed out my evaluation dimensions may need reference to prove the rigor of evaluation matrix, like how there dimensions are selected and 
what their connections and uniquenesses are. 

It is correct indeed that we take rigor in every step of doing research and building systems. Therefore, we will continue to work on 
reading papers about evaluation and creating effective evaluation matrix for our frame blender.

## To-do List For Next Week

- Continue with evaluation system, read papers and find effective evaluation matrix.
- Start doing documentation for frame blender.


## Weekly Meeting Slides Link

[Red Hen Meeting - Aug 09](https://docs.google.com/presentation/d/1QaXMAhFqpPkmi0tftTBFVZCfYtVvF40ARAXvx_yAtC8/edit)